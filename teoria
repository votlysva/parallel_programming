Вступление, модели, их свойства, согласованность
SMP (symmetric multiprocessing) – два или больше ядра, на каждом по потоку.

SMT (simultaneous multithreading) – два или больше потоков исполняются одним ядром.

NUMA (not uniform memory access) – все знают, что это еще с 1 курса.

Операционные системы (классификация по параллельности):

Однозадачные
Пакетные задания (batch processing)
Многозадачные
Кооперативная (cooperative) многозадачность. Переход от одной задачи к другой происходит явно, когда программа готова передать процессорное время другой.
Вытесняющая (preemptive) многозадачность. Текущий подвид – ОС сама расставляет инструкции как ей этого хочется.
Поток и процесс (на практике вперемешку):

Процесс – владеет памятью и ресурсами.
Поток – контекст исполнения внутри процесса.
Модели программирования:

Однопоточное/однозадачное.
Многозадачное:
Модель с общей памятью: Единственное, что объединяет потоки – общие объекты. Общий объект – переменная (read/write, тип). Иногда зовутся регистрами, так как на практике значения лежат как раз в регистрах ЦП.
Модель с передачей сообщений.
Модели исполнения:

Модель чередований Строим дерево, в котором описываем все возможные перестановки операций над общими объектами. Такая модель не описывает появление пары (0, 0) в следующем примере:
thread P {
       x = 1
       r1 = y
}
thread Q {
       y = 1
       r2 = x
}
    
Но оно может появиться вследствие того факта, что компилятор может переставить инструкции или же просто запись обоих значений будет отложена процессором.

Модель чередования не описывает конкретно физических реалий этого мира – ведь свет за один такт процессора проходит 10см, элементы просто физически не могут синхронизоваться.

Физическая – это световой конус.

Happens before Исполнение системы – пара $⟨H, →⟩$.
$H$ – множество операций (чтение и запись ячеек памяти)
$e → f$ значит, что $e$ произошло раньше $f$ – частичный строгий порядок на \(H\).
$a ∥ b$, если $¬(a → b ∨ b → a)$.
Модель глобального времени Каждая операция – интервал $[tinv, tresp]$, и если выражать через happens-before, то $a → b ≡ tresp(a) < tinv(b)$.
Конфликты:

Конфликт (data race) – ситуация, когда происходит две параллельных операции, и одна из них – запись.
Корректно синхронизированная программа – программа без конфликтов.
Исполнения:

Последовательное – все операции линейно упорядочены отношением happens-before (→). В модели глобального времени ничего не наслаивается вообще.
Правильное – сужение исполнения на один поток (только операции, приналежащие конкретному потоку) последовательно. Неправильные исполнения – вообще какая-то чепуха (параллельность в одном потоке). Или ”a = (b++) + (c++)” – undefined behavior в плюсах.
Допустимое последовательное исполнение – выполнены последовательные спецификации всех объектов. Посл. спецификация объекта – последовательность сужения исполнения на конкретный объект.
Условия согласованности:

Последовательная согласованность Исполнение посл. согласованно, если можно сопоставить ему допустимое последовательное исполнение, причем программный порядок (≡ порядок операций на каждом потоке) сохраняется.
Кстати последовательная согласованность на каждом объекте не влечет за собой последовательную согласованность исполнения.

Линеаризуемость Исполнение линеаризуемо, если можно сопоставить ему допустимое последовательное исполнение, которое сохраняет порядок happens-before.
Линеаризуемость локальна, линеаризуемость на каждом объекте влечет линеаризуемость системы. Операции над линеаризуемыми объектами называют атомарными. Исполнение системы, выполняющее операции над линеаризуемыми объектами, можно анализировать в модели чередования. Свойство thread-safe объекта есть ровно линеаризуемость.

Если в примере java-novolatile сделать x,y volatile, то пара $(0,0)$ не будет появляться, то есть исполнение действительно соответствует модели чередования.

Реализуется volatile в java локами памяти (memory lock). Тут мы немного теряем производительность, но не страшно.

Блокировки, взаимное исключение, deadlock’и
Линеаризуемость – суперское свойство. Даже если в каждом потоке все операции атомарны, мы не можем утверждать, что объект линеаризуем (ну представьте себе класс очереди с методами push/pop). Мы вот хотим линеаризуемую очередь.

Самый простой метод сделать так – это использование блокировок (locks, mutex (mutual exclusion)).

Идея: заведем в объекте member Mutex m, будем его лочить и разлочивать. Этот объект будет гарантировать, что объект будет застрявать на .lock, если мьютекс уже залочен и т.д. Код с mutex’ами будет thread-safe, если операции будут защищены одним и тем же мьютексом.

Взаимное исключения – свойство исполнения, при котором критические секции не могут выполняться параллельно – это требование корректности взаимного исключения.
При этом взаимное исключение имеет ряд условных условий прогресса:

Свобода взаимной блокировки (deadlock-freedom) – свойство взаимного исключения, при котором если несколько потоков пытаются войти в критическую секцию, то хотя бы один сделает это за конечное время (при условии что критические секции сами по себе конечны).
Отсутствие голодания (starvation-freedom) – если какой-то поток пытается войти в критическую секцию, он сделает это за конечное время (опять-таки, при условии, что крит. секции исп. за конечное время).
Линейное ожидание – каждый поток совершает $O(n)$ действий перед тем, как войти в критическую секцию (условие аналогично)
First Come First Served (FSFS) – свойство сильнее линейного ожидания, потоки обслуживаются в порядке утыкания в критическую секцию (условие аналогично).
Как написать mutex, собственно?

Aлгоритм Петерсона – гарантирует взаимное исключение, отсутствие взаимной блокировки и отсутствие голодания.
Преимущество – самый простой.

threadlocal int id // 0 or 1
shared boolean want[2]
shared int     victim

def lock:
    want[id] = true
    victim = id
    while (want[1-id] and victim == id) {}

def unlock:
    want[id] = false
    
Aлгоритм Петерсона для N потоков (filter algorithm).
Все то же самое, но может делать $O(N²)$ ожидания.

threadlocal int id
shared int level[N]
shared int victim[N]

def lock:
    for j = 1..N-1:
        level[id] = j
        victim[j] = id
        while exist k: k != id and
                       level[k] >= j and
                       victim[j] == id:
                       {}

def unlock:
    level[id] = 0
    
Алгоритм Лампорта (булочника – 1 вариант). Обладает свойством FCFS. Это вариант с бесконечными метками label. Можно сделать с конечными.
Первые две строки lock называются doorway.

threadlocal int id
shared boolean want[N]  // init false
shared int     label[N] // init 0

def lock:
    want[id] = true
    label[id] = max(label) + 1
    while exists k: k != id and
                    want[k] and
                    (label[k], k) < (label[id], id)
                    {}
    
Блокировки бывают грубыми и тонкими.

Грубая – блокировать всю операцию целиком.
Тонкая – блокировать операции над общими объектами внутри, а не вызов, но тогда необходима двухфазовая блокировка.
Есть проблема deadlock’а. Допустим, что есть два mutex’а, мы лочимся в одном треде сначала по m1, потом по m2, в другом треде наоборот. Можем задедлочиться тут короче.

Закон Амдала для параллельной работы: \[speedup = \frac{1}{(S + \frac{1-S}{N})}\] Это максимальное ускорение при запуске кода в $N$ потоков, если доля кода $S$ выполнена последовательно.

Алгоритмы/объекты без блокировок, свободы (lock/wait/obstr)
Алгоритмы без блокировок.

Безусловные условия прогресса:

Obstruction-free (отсутствие помех) – свойство алгоритма, в котором если остановить всe потоки кроме одного (любого) в любом месте, один должен завершиться за конечное время. Так должно работать для каждого объекта. Очевидно, что объект с блокировкой не имеет такого свойства.
Lock-freedom – если много потоков пытаются сделать операцию, то хотя бы один поток должен ее исполнить за конечное время. Плохо то, что это условие не исключает голодания.
Wait-freedom (самое сильное условие) – если какой-то поток пытается выполнить операцию, то он это сделает (вне зависимости от действия/бездействия других потоков).
Объекты без блокировки. ОБъекты бывают с lock-freedom, но этот термин перегружен.

Регистры без блокировки
Свойства физических регистров:
Неатомарны.
Работают без ожидания.
Предполагают только одного читателя и одного писателя.
Попытка записать и прочитать одновременно – UB.
Они безопасные (safe) – в смысле, после записи, будет прочитано последнее записанное значение.
Классификация регистров
По условиям согласованности:
Безопасные (safe) – гарантирует получение последнего записанного значения, если операция чтения не параллельна операции записи.
Регулярные (regular) – при чтении выдает последнее записанное, или то, что уже пишется.
Атомарные (atomic) – линеаризуемое (как регулярный, только если уже прочитал новое значение, то старое нельзя прочитать).
Как проверить регистр на атомарность в схеме глобального времени – поставить в каждой полоске точку, соответствующую этому конкретному действию. Порядок по точкам должен быть атомаррным.

По количеству потоков (SR, MR, SW, MW : single/multi reader/writer).
Будем строить более сложные регистры из простых требуя wait-free условие. Пусть у нас есть Safe SRSW Boolean регистр.
Regular SRSW Boolean.
safe shared boolean r
threadlocal boolean last

def write(x):
  if (x != last)
    last = x
    r = x

def read(): return r
            
Regular SRSW M-Valued.
Пусть у нас массив r хранит булевые значения, и число в нем хранится последовательностью единиц, терминированной нулем. Тогда это реализуется так:

regular shared boolean[M] r

def write(x): // Справа налево
  r[x] = 0
  for i = x-1 downto 0: r[i] = 1

def read(): // Слева направо
  for i = 0 to M-1: if r[i] == 0: return i
            
Atomic SRSW M-Valued.
Будем хранить пару – значение и версию. Версию можно разумно ограничить. Есть алгоритм без жульничества с версиями, но он на практике плох.

safe shared (int x, int v) r
threadlocal (int x, int v) lastRead
threadlocal int lastWriteV

def write(x):
  lastWriteV++
  r = (x, lastWriteV)

def read():
  cur = r
  if cur.v > lastRead.v:
    lastRead = cur
  return lastRead.x
            
Атомарный регистр: проблемы

Версии – могут хранить пару в регуярном, но версии растут неограниченно.
Блокировки – алгоритм Лампорта будет работать на регулярных регистрах, но это не дает алгоритм без ожидания.
Теорема: не существует алгоритма построения атомарного регистра без ожидания, который использует конечное число регулярных регистров конечного размера так, чтобы их писал только писатель, а читал только читатель
Доказательство Нужна обратная связь от читателя к писателю.
Atomic MRSW M-Valued.
Нужно отслеживать версию записанного значения, храня пару $(x, v)$ в каждом из $N$ регистров в которые пишет писатель. Наивно сделать это нельзя.

Заведем $N×(N-1)$ регистров для общения между читателями.

Каждый читатель выбирает более позднее значение из записанного писателем и из прочитанных значенией других читателей
Читатель записывает свое прочитанное значение и версию для всех остальных читателей.
Atomic MRMW M-Valued.
Нужна поддержка $N$ писателей.

Отслеживаем версию записанного значения:

Каждый читатель выбирает более позднюю версию
Для проставления версий писателями используем doorway секцию из алгоритма булочника (Лампорта)
Версия состоит из пары номера потока писателя и собственно числа
Атомарный снимок состояния N регистров.
Наивная реализация не обеспечивает атомарность.

Вот этот алгоритм уже lock-free, но достаточно наивный – читает, пока массивы не совпадут.

shared (int x, int v) r[N]

// wait-free
def update(i, x):
    r[i] = (x, r[i].v + 1)

// lock-free
def scan():
    old = copy()
    loop:
        cur = copy()
        if forall i: cur[i].v == old[i].v
           return cur.x  // we can get starvation here,
                         // if update is executed too frequent
        old = cur
        
Вот wait-free реализация с костылями.

shared (int x, int v, int[N] s) r[N]

def update():
    s = scan()
    r[i] = (x, r[i].v + 1, s)

shared (int x, int v, int[N] s) r[N]

// wait-free, O(N^2)
def scan():
    old = copy()
    boolean updated[N]
    loop:
        cur = copy()
        for i = 0..N-1:
            if cur[i].v != old[i].v:
               if updated[i]: return cur.s
               else:
                update[i] = true
                old = cur
                continue loop
        return cur.x
        
Лемма: Если значение поменялось второй раз, значит копия снимка $s$ была получена вложенной операцией scan.
Консенсус
Консенсус – это объект, который помогает $n$ потокам придти к общему мнению.

class Consensus:
      def decide(val):
      ...
      return decision
Каждый поток использует объект Consensus один раз. Требуются две вещи:

Согласованность (consistency): все потоки должны вернуть одно и то же значение из метода decide.
Обоснованность (validity): возвращенное значение было входным значением какого-то из потоков.
shared int decision
Mutex mutex

def decide(val):
    mutex.lock()
    if (decision == NA):
       decision = val
    mutex.unlock()
    return decision
Но мы хотим без ожидания.

Все не так просто. Консенсусное число:

Если с помощью класса атомарных объектов $С$ и атомарных регистров можно реализовать консенсусный протокол без ожидания для $N$ потоков (и не больше), то говорят что у класса $С$ консенсусное число равно $N$.
Теорема: Атомарные регистры имеют консенсусное число 1.
То есть с помощью атомарных регистров даже 2 потока не могут придти к консенсусу без ожидания (докажем от противного) для 2х возможных значений при $T = \{0, 1\}$
С ожиданием задача решается очевидно (с помощью любого алгоритма взаимного исключения).
Определения и леммы для любых классов объектов:
Определения и концепции
Исходныe объекты атомарны. Любое исполнение можно рассматривать как последовательное в каком-то порядке.
Рассматриваем дерево состояния, листья – конечные состояния помеченные 0 или 1 (в зависимости от значения консенсуса).
x-валентное состояние системы ($x ∈ \{0,1\}$) – консенсус по всех нижестоящих листьях будет x.
Бивалентное состояние – возможен консенсус как 0 так и 1.
Критическое состояние – такое бивалентное состояние, все дети которого одновалентны.
Лемма: Существует начальное бивалентное состояние.
Это нетривиально следует из того факта, что алгоритм без ожиданий.

Возьмем конечное количество шагов, построим дерево. $???$ Доказательство было на доске и не сохранилось.

Лемма: Существует критическое состояние
Тоже следует из wait-free. Если есть бивалентное, будем смотреть его детей. Если есть хотя бы один бивалентный ребенок, то спускаемся в него, пока бивалентных детей больше нету. За счет конечности дерева такое будет существовать, и валентность детей будет различна (иначе валентность самого узла тоже определена).

Для атомарных регистров рассмотрим возможные пары операций в критическом состоянии:

Операции над разными регистрами коммутируют.
Два чтения коммутируют.
Любая операция + запись – состояние пишущего потока не зависит от порядка операций. Противоречие (в чем???).
Бывают Read-Modify-Write регистры.
class RMWRegister:
      private shared int reg

      def read():
          return reg

      def getAndF(args):
          do atomically:
             old = reg
             reg = F(args)(reg)
             return old
    
Функция F может быть getAndSet, getAndIncrement,…

threadlocal int id // 0 or 1

shared RMWRegister rmw
shared int proposed[2]

def decide(val):
    proposed[id] = val
    if (rmw.getAndF() == v0)
        return proposed[i]
    else:
        return proposed[1-i]
    
Консенсусное число нетривиального RMW регистра $≥ 2$.
Нужно чтобы была хотя бы одна подвижная точка функции $F$, например $F(v_0) = v_1 ≠ v_0$.

Common2 RMW регистры
$F_1$ и $F_2$ коммутируют если $F_1(F_2(x)) = F_2(F_1(x))$.
$F_1$ перезаписывает $F_2$ если $F_1(F_2(x)) = F_1(x)$.
Класс $С$ RMW регистров принадлежит Common2 если любая пара функций либо коммутирует либо одна из функций перезаписывает другую.
Теорема: нетривиальный класс Common2 RMW регистров имеет консенсусное число 2.
Третий поток не может отличить глобальное состояние при изменении порядка выполнения коммутирующих или перезаписывающих операций в критическом состоянии.

Универсальные объекты Объект с консенсусным числом $∞$ называется универсальным объектом. По определению, с его помощью можно реализовать консенсусный протокол для любого числа потоков.
class CASRegister:
      private shared int reg

      def CAS(expect, update):
          do atomically:
             old = reg
             if old == expect:
                reg = update
                return true
             return false
    
CAS – самый популярный универсальный объект, процессоры в том или ином виде его реализуют.

CAS и консенсус
def decide(val):
    if CAS(NA, val):
        return val
    else:
        return read()
        
Универсальность консенсуса. Теорема. Любой последовательый объект можно реализовать без ожидания для N потоков используя консенсусный протокол для N объектов
Такое построение – универсальная конструкция
Следствие 1: С помощью любого класса объектов с консенсусным числом N можно реализовать любой объект с консенсусным числом ≤ N
Следствие 2: С помощью универсального объекта можно реализовать вообще любой объект
Сначала реализуем консенсус для любого числа потоков (по определению универсального объекта)
Потом через консенсус любой другой объект используя универсальную конструкцию.
Доказательство теоремы
Универсальная конструкция без блокировки через CAS
shared CASRegister reg

def concurrentOperationX(args):
    loop:
        old = reg.read()
        upd = old.deepCopy()
        res = upd.serialOperationX(args)
    until reg.CAS(old, upd)
    return res
                
Без блокировки универсальная конструкция проста и проктична, если использовать CAS в качестве примитива.
Для реализации через консенсус надо чтобы каждый объект консенсуса пользовался потоком один раз
Для реализации без ожидания нужно чтобы потоки помогали друг другу.
Через консенсус.
ОБъект – односвязный список стейтов. Последний элемент – текущий стейт.

class Node:
      val               // readonly
      Consensus next    // init fresh obj

shared Node root        // readonly
threadlocal Node last   // init rood

def concurrentOperationX(args):
    loop:
        old = last.val
        upd = old.deepCopy()
        res = upd.serialOperationX(args)
        node = new Node(upd)
        last = last.next.decide(node)
    until last == node
    return res
                
Но с ожиданием
Через консенсус без ожидания
Храним в узле операцию, которую нужно выполнить, а не результат – каждый поток обновляет и хранит свою локальную копию объекта
Нумеруем операции последовательными числами, заведя переменную seq. После выполнения прописываем номер исполненной операции.
Каждй поток хранит последнее ему известное значение конца списка в элементе массива know[id].
Каждый поток будет заранее записывать операцию, которую он планирует выполнить – в массиве announce.
class Node:
      int seq           // init 0
      args              // readonly
      Consensus next    // init fresh obj

shared Node[] announce // init root
shared Node[] know // init root

def concunrrentOperationX(args):
    announce[id] = new Node(args)
    know[id] = maxSeqFrom(know)
    while announce[id].seq == 0
          Node help =
               announce[know[id].seq % N]
          Node prev = help if help.seq == 0
               else announce[id]
          know[id] = prev.next.decide(node)
          know[id].seq = prev.seq + 1
    know[id] = announce[id]
    return updateMyLastTo(announce[id])

def updateMyLastTo(node):
    while last != node:
          res = my.serialOperationX(last.args)
          last = last.next
          return res
                
Сводная иерархия
Объект	Консенсусное число
Атомарные регистры	1
Снимок состояния нескольких регистров	
getAndSet, getAndAdd, очередь, стек	2
Атомарная запись m регистров из m(m+1)/2	m
compareAndSet, LoadLinked/StoreConditional	∞
Практические построения на списке, вступление
Будем смотреть всякие практические построения на списках. Будем писать код уже на джаве настоящей.

Java – первый язык, в котором появилась модель памяти (memory model). Почему джава? Трюки c++ (if_arch_…) не работают в джаве, джава очень WORA, и прочее.

JMM определяет:

Межпоточные действия – чтение и запись, синхронизация. Синхронизация – ~volatile~/~synchronized~/запуск или остановка потоков.
Отношение синхронизации (synchronizes-with) и отношение happens-before. Java гарантирует, что если в программе нету гонок, то исполнение последовательно согласовано (а значит и линеаризуемо).
Всякие гонки и прочее.
Выполнение корректно синхронизированной программы будет выглядеть последовательно согласовано. Гонки за данными не могут нарушить базовые гарантии безопасности платформы (система типов, все кроме long/double атомарны, все поля гарантированно инициализированы нулями, дополнительные гарантии для final полей).

volatile int flag;
int value;

void int() {
    value = 2;
    flag = 1;
}

int take() {
    while (flag == 0); // кушаем cpu тут
    return value;
}
int flag, value;

void synchronized int() {
    value = 2;
    flag = 1;
}

int synchronized take() {
    while (flag == 0); // кушаем cpu тут
    return value;
}
Таким образом, мы реализовали thread-safe объект.

Типы синхронизации на примере списка (LinkedSet)
Многопоточные объект – это объект, который можно использовать из нескольких потоков без дополнительной внешней синхронизации, при этом:
Специфицируется через последовательное поведение.
По умолчанию требуется линеаризуемость операций (редко – более слабые условия).
Редко удается реализовать все операции wait-free. Чаще всего делается с блокировками или без них (что на самом деле lock-free).
Типы синхронизации:

Грубая синронизация (Coarse-grained).
Тонкая (fine-grained).
Оптимистичная (optimistic).
Ленивая (lazy).
Неблокирующая (non-blocking).
Будем строить многопоточные связанные списки. Массивами пользоваться намного эффективней, но они сложнее пишутся.

// инвариант node.key < node.next.key
class Node {
    final int key;
    final T item;
    Node next;
}
Пустой список будет состоять из 2х граничных элементов:

Node head = Node(Integer.MIN_VALUE, null);
head.next = Node(Integer.MAX_VALUE, null);
Грубая синхронизация
Обеспечиваем синхронизацию через java.util.concurrent.locks.ReentrantLock lock. Такой подход дает немножко больше функционала чем секции synchronized.

class LinkedSet {
    final Node head;
    final Lock lock; // mutex

    boolean contains(int key) {
        lock.lock();
        try {
            Node curr = head;
            while (curr.key < key) {
                curr = curr.next;
            }
            return key == curr.key;
        } finally { lock.unlock() }
    }

    boolean add(int key, T item) {
        lock.lock();
        try {
            Node pred = head, curr = pred.next;
            while (...) {}
                /// stuff
        } finally { lock.unlock(); }
    }
    boolean remove (int key, T item) {
        lock.lock();
        try {
            // stuff
        } finally { lock.unlock; }
    }
}
Тонкая синхронизация
Обеспечиваем синхроизацию взаимным исключением на каждом объекте. При любых операциях одновременно удерживаем блокировку текущего и предыдущего элемента, чтобы не потерять инвариант pred.next == curr.

class Node {
    final int key;
    final T item;
    final Lock lock;
    Node next;

    void lock() { lock.lock(); }
    void unlock() { lock.unlock(); }
}

class LinkedSet {
    boolean contains() {
        Node pred = head; pred.lock();
        Node curr = pred.next; curr.lock();
        try {
            while (curr.key < key) {
                // отпускаем блокировку у предыдущего объекта
                // берем у следующего.
                pred.unlock();
                pred = curr;
                curr = curr.next;
                curr.lock();
            }
            return key == curr.key;
        } finally { curr.unlock(); pred.unlock(); }
    }

    boolean add(int key, T item) {
        Node pred = head; pred.lock();
        Node curr = pred.next; curr.lock();
        try {
            // addition
            while (curr.key < key) {
                pred.unlock(); pred = curr;
                curr = curr.next; curr.lock();
            }
            if (key == curr.key) return false; else {
                Node node = new Node(key, item);
                node.next = curr; pred.next = node;
                return true;
            }
        } finally { curr.unlock; pred.unlock; }
    }

    boolean remove(int key, T item) {
        Node pred = head; pred.lock();
        Node curr = pred.next; curr.lock();
        try {
            // removal
        } finally { curr.unlock; pred.unlock; }

    }
}
Оптимистичная синхронизация
Алгоритм построения:

Ищем элемент без синхронизации, но перепроверяем с синхронизацией.
Если перепроверка сломалась, то начинаем операцию заново
Поиск не зациклится, ибо ключи упорядочены, никогда не меняются внутри Node, значения next не могут возникнуть ниоткуда даже при чтении без синхронизации
Имеет смысл только если обход дешев и быстр, а обход с синхронизацией – наоборот.
Потоки всегда синхронизируются между собой (“synchronizes with”) через критические секции, поэтому никаких дополнительных механизмов не нужно.
class LinkedSet {
    // проверяет, что pred является предыдущим для curr
    // идет от начала списка до pred оптимистично, там сравнивает
    boolean validate(Node pred, Node curr) {
        Node node = head;
        while (node.key <= pred.key) {
            if (node == pred) {
                return pred.next == curr;
            }
            node = node.next;
            if (node == null) return false;
        }
    }

    boolean contains(int key) {
    retry: while (true) {
            Node pred = head, curr = pred.next;
            while (curr.key < key) {
                pred = curr; curr = curr.next;
                if (curr == null) continue retry;
            }
            pred.lock(); curr.lock();
            try {
                if (!validate(pred, curr)) continue retry;
                return curr.key == key;
            } finally { curr.unlock(); pred.unlock();
            }
        }
    }
    boolean add(int key, T item) {
    retry: while (true) {
            Node pred = head, curr = pred.next;
            while (curr.key < key) {
                pred = curr; curr = curr.next;
                if (curr == null) continue retry;
            }
            pred.lock(); curr.lock();
            try {
                if (!validate(pred, curr)) continue retry;
                if (curr.key == key) return false; else {
                    Node node = new Node(key, item);
                    node.next = curr; pred.next = node;
                    return true;
                }
            } finally { curr.unlock(); pred.unlock(); }
        }
    }
    // remove аналогично
}
Ленивая синхронизация
Как строить:

Добавляем в Node boolean флажок, в котором будем помечать удаленные элементы. Удаление в две фазы – флажок помечен соответствует логическому удалению, физическое следует позже.
Инвариант: все непомеченные элементы всегда в списке.
Результат: для валидации не надо просматривать список (только проверить, что элементы не удалены логически и pred.curr == next), остальное как в оптимистичном варианте.
Поиск без ожидания:

class Node {
    final int key;
    final T item;
    final Lock lock;
    boolean marked;
    // Очень важен volatile для линеаризуемости!
    volatile Node next;

    void lock() { lock.lock(); }
    void unlock() { lock.unlock(); }
}

class LinkedSet {
    boolean validate(Node prev, Node next) {
        return !pred.marked &&
            !curr.marked &&
            pred.next == curr;
    }

    boolean add(T elem) {
    retry: while (true) {
            Node pred = head, curr = pred.next;
            while (curr.key < key) {
                pred = curr; curr = curr.next;
                //                   ^^^^^^
                //            тут curr.next != null
            }
            pred.lock(); curr.lock();
            try {
                if (!validate(pred,curr)) continue retry;
                if (curr.key == key) {
                    curr.marked = true; // для validate
                    pred.next = curr.next; // точка линеаризации
                    return true;
                } else return false;
            } finally { curr.unlock(); pred.unlock(); }
        }
    }

    void delete (T elem) {
    retry: while (true) {
            Node pred = head, curr = pred.next;
            while (curr.key < key) {
                pred = curr; curr = curr.next;
                //                   ^^^^^^
                //            тут curr.next != null
            }
            pred.lock(); curr.lock();
            try {
                if (!validate(pred,curr)) continue retry;
                if (curr.key == key) return false;
                else {
                    Node node = new Node(key, item);
                    node.next = curr; // сначала! порядок важен
                    pred.next = node; // тут точка линеаризации
                    return true;
                }
            } finally { curr.unlock(); pred.unlock(); }
        }
    }

    // Wait-free поиск!
    boolean contains(int key) {
        Node curr = head;
        while (curr.key < key) {
            curr = curr.next; // точка линеаризации
        }
        return key == curr.key;
    }
}
Неблокирующая синхронизация
Сделать синхронизацию без блокировок нетривиально:

Простое использование CAS не помогает – удаление двух соседних элементов будет конфликтовать 1, 2, 3, 4, удалим 2, 3 одновременно, но указатель 1 → 3 сохранится.
Трюк такой: объединим (next, marked) в одну переменную, и будем ее изменять CASом атомарно.
Одновременное удаление соседних двух элементов будет конфликтовать
Каждая операция модификации выполняется одним успешным CAS’ом.
Это выполнение CAS’а и есть точка линеаризации
Будем пытаться удалять физически, от этого добавление и удаление станут lock-free, а поиск вообще wait-free.
В реализации будем использовать для пары java.util.concurrent.atomic.AtomicMarkableReference.
Продолжение построений на списках, стеках
Можно строить структуры универсально, храня на нее указатель и меняя его CAS’ом каждый раз. Так, например, работает счетчик – в джаве это AtomicInteger.

Персистентные структуры тоже несложно пишутся, достаточно заменить CAS’ом root на новый после изменения структуры. Остальное дерево остается прежней версии (персистентность, собсна).

Стек LIFO
Рассмотрим частный, вырожденный случай древовидной структуры – стек. Он не масштабируемый. Если конкуренция очень большая, то производительность в многосокетных системах на top будет падать.

   // such immutable!
   class Node {
       final T item;
       final Node next;
   }

   final AtomicReference<Node> top = new AtomicReference<Node>(null);

   void push(T item) {
        while (true) {
              Node node = new Node(item, top.get());
              if (top.compareAndSet(node.next, node)) // линеаризация
                 return;
        }
   }

   T pop() {
     while (true) {
           Node node = top.get();

if (node == null) throw new EmptyStack();
           if (top.compareAndSet(node, node.next)) // линеаризация
              return node.item;
     }
   }
С разделяемой памятью вообще все достаточно сложно, там не только race condition’ы в большом количестве, но и куча проблем с производительностью. Будем пока считать что стек хороший.

Очереди на списках, Майкл-Скотт
Будем делать очередь на списках. Наивно с помощью универсальной конструкции так себе, а популярный алгоритм – Майкла Скотта.

Делаем список, у очереди есть указатель на голову и хвост, все односвязно. Будем элементы добавлять и удалять достаточно естественно. Добавление: Создаем элемент, ссылаемся на голову, с помощью CAS’а меняем указатель на голову в классе. Дописать элемент в хвост сложно, потому что нужно поменять сразу две ячейки памяти – указатель класса на хвост, указатель предыдущего элемента хвоста на последний.

Идея алгоритма Майкла-Скотта такая: будем брать элемент и подписывать его в хвост, меняя ссылку предыдущего, а физически перемещать tail (указатель из класса) потом. Если другой поток увидит, что очередь в состоянии “есть ссылка на tail, у которого есть следующий элемент”, то он может помочь переставить указатель класса на нужный элемент.

class Node {
    T item;
    final AtomicReference<Node> next;
}

AtomicReference<Node> head =
    new AtomicReference<Node>(new Node(null));
AtomicReference<Node> tail =
    new AtomicReference<Node>(head.get());

void enqueue(T item) {
    Node node = new Node(item);
 retry: while (true) {
        Node last = tail.get(),
            next = last.next.get();
        if (next == null) {
            if (!last.next.compareAndSet(null, node))
                continue retry;
            // оптимизация -- сами переставляем tail
            tail.compareAndSet(last, node);
            return;
        }
        // помогаем другим операциям enqueue с tail
        tail.compareAndSet(last, next);
    }
}

T dequeue() {
 retry: while (true) {
        Node first = head.get(),
            last = tail.get(),
            next = first.next();
        if (first == last) {
            if (next == null) throw new EmptyQueue();
            // Помогаем операциям enqueue с tail
            tail.compareAndSet(last, next);
        } else {
            if (head.compareAndSet(first, next)) // линеаризация
                return next.item;
        }
    }
}
ABA problem
Есть проблема в средах без сборки мусора, называется ABA. Суть: Будем реализовывать самый первый стек этой лекции на C, без Garbage collector’а. Добавим в стек несколько элементов – A и B. Может быть такое, что top стека может быть: A B A. Достанем указатель на top, сделаем успешно cas, на return нас перебил другой поток, и что-то переаллочилось, теперь в A лежит какая-то другая фигня.

Еще раз: в стеке 1 элемент, по адресу A (top = A). Мы делаем ему pop, достаем A. В это время нас прерывают. Другой поток делает pop A, push B, pop B, push C на месте A появился другой элемент, но CAS сравнивает только указатели, и в этом случае он не обнаружит эту проблему. В джаве это не работает так, потому что память на A нельзя освободить, пока на нее ссылаются.

Решить ABA проще всего с помощью реализации сборщика мусора. Другой способ – пользоваться версиями. Хранить в top пару из указателя и версии. Таким образом если стек за время top.get и cas успел поменяться, мы сравним версии и упадем. Именно поэтому мы можем делать cas на 2х последовательных словах, это позволяет нам менять одновременно указатель + версию. Еще можно пользоваться Hazard Pointers – многопоточный сборщик мусора, который работает только для наших узлов.

Алгоритмы на массивах
Стек на массиве
Давайте делать стек на массиве.

В однопоточном варианте стек на массиве – очень просто. Типа держим размер, pop/push меняет размер массива и ячейку. Но это все равно не взлетит в многопоточном варианте совсем прям наивно.

Вот делаем мы push. Сначала увеличим top cas’ом, а потом проставим элемент. Push будет работать, но pop в такой реализации упадет – если мы уже увеличили top, но не положили элемент, то достанет какой-то мусор.

Аналогично если сначала проставляем элемент, а потом увеличиваем top, то там будет что-то старое.

С очередями проблемы те же.

Будем писать дек, пытаясь реализовать obstruction-free свойство. Дек будет циклическим. Храним в элементе пару – значение и версия. Там где дек пустой, будем хранить (left_null, version), справа (right_null, version).

Для корректности алгоритма не будем полагаться на указатели left и right в классе дека – они будут типа для производительности, а индексироваться будем за $O(n)$.

На практике этим никто не пользуется, потому что все равно медленнее, чем на ссылочном листе.

int rightOracle() {
    int k = right; // для оптимизации
    while (a[k] != RN) k++;
    while (a[k-1] == RN) k--;
    right = k; // запомнили для оптимизации
    return k;
}

void rightPush(T item) {
 retry: while (true) {
        int k = rightOracle();
        {T item, int ver} prev = a[k-1], cur = a[k];
        if (prev.item == RN || cur.item != RN) continue;
        if (k == MAX-1) throw new FullDeque();
        if (CAS(a[k-1], prev, {prev.item, prev.ver+1} &&
                CAS(a[k], cur, {item, cur.ver+1}))) return;
    }
}

T rightPop() {
 retry: while (true) {
        int k = oracleRight();
        {T item, int ver} cur = a[k-1], next = a[k];
        if (cur.itim == RN || next.item != RN) continue;
        if (cur.item == LN) throw new EmptyDeque();
        if (CAS(a[k], next, {RN, next.ver+1}) &&
            CAS(a[k-1], cur, {RN, cur.ver + 1}))
            return cur.item;
    }
}
Хэш-таблицы на массиве
Бывают с прямой адресацией (по хэшу находим ведро, и все элементы с таким хэшом попадают в это ведро – там дальше список или дерево). На практике с прямой адресацией все медленно, потому что там опять массивы или списки. Бывают с открытой, это самый лучший вариант. Но со списками намного проще.

Будем пользоваться алгоритмом Split-Ordered lists. Засунем все элементы в одно большое связанео множество. Упорядочим их по хэшу. Для ускорения заведем слева хэш-таблицу, адресующую те элементы листа с заданным хэшом. Эта дополнительная таблица делается только для ускорения. Когда будем хотеть расширить таблицу, создадим вторую, скопируем ее черезстрочно, будем по мере обращений к хэшу ее обновлять (вторую).

Открытая адресация. Делаем на массиве, будем считать ведро по хэшкоду, если занято, то дальше. Добавлять из нескольких потоков легко – просто делаем cas. Удалять из такой таблицы можно прописывая некоторое особенное значение T. Нельзя прудмать алгоритм, который бы многопоточно закрывал дырки в этих списках. Ну, допустим мы забиваем элементы T, но как перевыделять память со временем – для освобождения элементов T или расширения таблицы.

Сделаем так, что таблица хранит указатель на “реальную” внутреннюю таблицу. Когда копируем, создаем новую таблицу, а указатель поставим в конце. Операция изменения ищет в новой таблице, если нету, то ищет в старой, если находит – копирует в новую. Таким образом мы перенесем все элементы в новую таблицу. Как переносить, собственно?

Если собираемся переносить, то пометим битиком значение. После этого мы занимаем слот в новой таблице, после этого копируем значение в новой таблице. Затем в старой пометим, что мы уже скопировали.

(0, 0)
   ↓
{Claim key}
   ↓
(K, 0)
   ↓
{Set value}
   ↓
(K, V)            → Start copy → (K, V')
   ↕                               ↑
{insert/delete}                  Moved
   ↕                               ↑
(K, T)            → Moved      → (K, T')
CASN
Этот алгоритм с переносом таблиц есть частный случай. Хотим чтобы работало корректно (линеаризуемо) и:

Lock-free.
Disjoint-Access Parallel (непересекающиеся доступы параллельны).
boolean CASN(CASEntry... entries) atomic {
    for (CASEntry entry: entries)
        if (entry.a.value != entry.expect)
            return false;
    for (CASEntry entry: entries)
        entry.a.value = entry.update;
    return true;
}
Если мы сделаем CASN, то сделаем стек на массиве – будем одновременно делать CAS 2 раза.

import java.util.concurrent.atomic.AtomicReferenceFieldUpdater;

public class CASEntry<T> {
    final DataReference<T> a; // что поменять
    final T expect; // ожидаемое значение
    final T update; // на что заменить
    // И тут простой конструктор для всех трех полей
}

// RDCSS сложна, только если ячейка может страдать от ABA.
// Если нет, то проще.
class RDCSSDescriptor {
    private final DataReference a1;
    private final Object expect1;
    private final DataReference a2;
    private final Object expect2;

    private final Object update2;
    // и конструктор

    Object invoke() {
        Object r;
        do {
            r = a2.getAndCAS(expect2, this);
            if (r instanceof RDCSSDescriptor)
                ((RDCSSDescriptor)r).complete();
        } while (r instanceof RDCSSDescriptor);
        if (r == expect2) complete();
        return r;
    }

    void complete() {
        if (a1.value == expect1) a2.CAS(this, update2);
        else a2.CAS(this.expect2);
    }
}

enum Status {
    UNDECINED, SUCCEEDED, FAILED
}

class CASNDescriptor {
    private final DataReference status =
        new DataReference(Status.UNDECINED);
    private final CASEntry[] entries;

    // надо гарантировать одинаковый порядок обработки
    // DataReference каждым CASN, их надо как-то упорядочить
    CASNDescriptor(CASEntry[] entries) {
        this.entries = entries;
        Arrays.sort(this.entries);
    }

    boolean complete() {
        if (status.value == Status.UNDECINED) {
            Status newStatus = Status.SUCCEEDED;
            for (int i = 0; i < entries.length;) {
                CASEntry entry = entries[i];
                // AQUIRE ENTRY
                Object val = new RDCSSDescriptor(this.status,
                                                 Status.UNDECIDED,
                                                 entry.a,
                                                 entry.expect,
                                                 this).invoke();
                // AQUIRE ENTRY END

                if (val instanceof CASNDescriptor) {
                    if (val != this) {
                        ((CASNDescriptor)val).complete();
                        continue; // retry this entry
                    }
                } else if (val != entry.expect) {
                    newStatus = Status.FAILED;
                    break;
                }
                i++; // go to next entry
            }
            this.status.CAS(Status.UNDECIDED, newStatus);
        }
        boolean succeeded = status.value == Status.SUCCEEDED;
        for (CASEntry entry : entries) {
            // RELEASE
            entry.a.CAS(this, succeeded ? entry.update : entry.expect);
        }
        return succeeded;
    }
}

public class DataReference<T> {
    // хранимое значение
    volatile Object value;

    private static final
      AtomicReferenceFieldUpdater<DataReference, Object>
        VALUE_UPDATER =
          AtomicReferenceFieldUpdater.newUpdater(
            DataReference.class, Object.class, "value");

    boolean CAS(Object expect, Object update) {
        return VALUE_UPDATER.compareAndSet(this, expect, update);
    }

    Object getAndCAS(Object expect, Object update) {
        do {
            Object curval = value;
            if (curval != expect) return curval;
        } while (!CAS(expect, update));
        return expect;
    }

    public T get() {
        while (true) {
            Object curval = value;
            if (curval instanceof RDCSSDescriptor) {
                ((RDCSSDescriptor)curval).complete();
                continue;
            }
            if (curval instanceof CASNDescriptor) {
                ((CASNDescriptor)curval).complete();
                continue; // retry
            }
            return (T)curval;
        }
    }

    public T get();
    public static boolean CASN(CASEntry... entries);
}
Сложные блокировки
Проведем анализ конфликтов (data race) – два несинхронизированных доступа к одной ячейке данных, один из которых запись.

Матрица конфликтов (для регистра) – какие методы конфликтуют:

R	W
R		×
W	×	×
Подход этой матрицы позволяет чисто автоматизированно составить матрицу для сложной структуры с большим количеством методов.

Можно тривиально убрать конфликты с помощью грубой блокировки на каждом конфликтующем методе. С другой стороны, жиненная ситуация – после грубой блокировки некоторые методы могут работать одновременно (к примеру только читающие методы).

Эту проблему решают read-write locks. Можем создать класс, который умеет лочиться по read или по write. Такой класс будет принимать сколько угодно локов по read, но остальные не будут совместимы.

Другое решение – делать структуру данных, используя тонкую блокировку. Например, с помощью CASN.

Как сделать линеаризуемый многопоточный объект?

Блокировки (aka synchronized): грубая, тонкая, …, read-write.
Без блокировки
Универсальная конструкция (Copy-on-write + CAS, частичное копирование + CAS).
CASN.
Специфичные для структуры алгоритмы.
Проблемы блокировки:

В системе нет прогресса, пока объект заблокирован.
Требуются дополнительные переключения контекста чтобы дать закончить работу блокирующему потоку. Это может сильно жрать CPU.
Минимальный параллелизм работы, причем параллелизм обратно пропорционален количеству блокировок.
Deadlocks.
STM
Как делать сложные вещи и не думать? STM! Типа навешиваем какие-то вещи на кусок кода, и он выполняется атомарно. Такое есть, например, в Clojure. И в хаскеле тоже есть! Проблема – оно работает медленно и поэтому не подходит для плюсов/джавы.

public class Employees {
    Set working = new ConcurrentSet();
    Set vacating = new ConcurrentSet();

    // псевдокод
    public boolean contains(Employee e) {
        atomic {
            return working.contains(e) ||
                vaccating.contains(e);
        }
    }

    public void startVacation(Employee e) {
        atomic {
            working.remove(e);
            vacating.add(e);
        }
    }
}
Будем писать класс транзакций и класс переменной для транзакции.

Транзакции с блокировкой:
Можно двухфазовой блокировкой. Все конфликтующие блокировки защищаются локами, в начале транзакции локи накапливаются, в конце отпускаются.
Тогда любое исполнение такой системы будет линеаризуемо
public class Transaction {
    private static final ThreadLocal<Transaction> CURRENT =
        new ThreadLocal<Transaction>();

    private final List<Lock> locks = new ArrayList<Lock>();

    private final Set<TVar<?>> writes = new HashSet<TVar<?>>();

    public void addWrite(TVar<?> var) {
        writes.add(var);
    }

    void addLock(Lock lock) { locks.add(lock); }

    // commit с блокировкой
    public boolean commit() {
        for (Lock lock : locks) lock.unlock();
        return true;
    }

    public void rollback() {
        for (TVar<?> var : writes) var.rollback();
        for (Lock lock : locks) lock.unlock();
    }

    public static Transaction beginTransaction() {
        Transaction t = new Transaction();
        CURRENT.set(t);
        return t;
    }

    public static Transaction currentTransaction() {
        return CURRENT.get();
    }

    public static <R> R atomic(AtomicBlock<R> call) {
        for (;;) {
            Transacion t = beginTransaction();
            try {
                R result = call.call();
                if (t.commit()) return result;
            } catch (RuntimeException | Error e) {
                t.rollback();
                throw e;
            }
        }
    }
}

public class TVar<T> {
    private T value;
    private final ReadWriteLock lock =
        new ReentrantReadWriteLock();

    // для rollback в Transaction
    private static final Object UNDEFINED = new Object();
    private Object oldValue = UNDEFINED;

    public T get() {
        lock.readLock().lock();
        Transaction.currentTransaction().addLock(lock.readLock());
        return value;
    }

    public void set(T value) {
        if (oldValue = UNDEFINED) {
            lock.writeLock().lock();
            this.oldValue = this.value;
            Transaction.currentTransaction().addWrite(this);
        }
        this.value = value;
    }

    void rollback() {
        value = (T)oldValue;
        oldValue = UNDEFINED;
        lock.writeLock().unlock();
    }
}
Транзакции без блокировки
Предоставим реализацию без помех. Разные потоки могут бесконечно долго мешать друг другу закончить транзакцию без прогресса, но если активен только один поток, то прогресс гарантирован.

Проблематика – даже читающие транзакции конфликтуют. В этом смысле решение с блокировкой лучше.

public class Transaction {
    private static final int ACTIVE = 0;
    private static final int COMITED = 1;
    private static final int ABORTED = -1;
    private final AtomicInteger state = new AtomicInteger(ACTIVE);

    public boolean isCommited() {
        return state.get() == COMMITED;
    }
    public boolean commit() {
        return state.compareAndSet(ACTIVE, COMMITED);
    }
    public void rollback() {
        state.compareAndSet(ACTIVE, ABORTED);
    }
    class VarHolder<T> {
        final Transaction owner;
        final Object value;
        Object newValue; // updated by owner

        VarHolder(Transaction owner, Object value) {
            this.owner = owner;
            this.value = value;
            this.newValue = value;
        }

        // текущее значение зависит от состояния владельца
        T current() {
            return owner.isCommited() ? (T)newValue : (T)value;
        }
    }
}

public class TVar<T> {
    private AtomicReference<VarHolder<T>> holder =
        new AtomicReference<VarHolder<T>>();

    public T get() {
        return (T)open().newValue;
    }

    public void set(T value) {
        open().newValue = value;
    }

    // переменную нужно открыть перед любым доступом
    VarHolder<T> open() {
        Transaction tx = Transaction.current();
        VarHolder<T> old, upd;
        do {
            old = holder.get();
            if (old.owner == tx) return old;
            old.owner.rollback(); // если активен
            upd = new VarHolder<T>(tx, old.current());
        } while (!holder.compareAndSet(old, upd));
        return upd
    }
}
Параллельно читать можно, для этого необходимо в TVar при чтении не открывать переменную. Значение тогда сможет поменяться в процессе транзакции, и линеаризуемость пропадает.

Решить это можно с помощью пост-проверки транзакции на корректность. Или с помощью многоверсионного контроля корректности.

Мониторы и локи
Представим операцию как функцию над парой из состояния и аргументов. Раньше мы рассматривали функции тлоько всюду определенные.

Возьмем блокирующую очередь. Пусть put кладет только, если есть место. Если нету, то она зависает, то есть put частично определена. Аналогично предтсавим себе take, который может вытаскивать элемент из очереди только, если очередь не пуста. Будем поддерживать, с другой стороны, и не блокирующиеся операции – size, offer, poll (возвращает null если пуста).

Примечание: тут блокировка обозначает нечто другое – определенность функции.

Тут нужно переопределить линеаризуемость и исполнение:

$inv(A)$ – это вызов, но не всегда есть $resp(A)$. $A$ называется незавершенной операцией, а $inv(A)$ незавершенным вызовом.
Исполнение линеаризуемо, если в исполнении можно:
Добавить такие ответы для незавершенных вызовов.
Выкинуть остальные незавершенные вызовы.
Можно упорядочить, получить допустимое последовательное исполнение: \[inv(A₁) → resp(A₁) → ⋯ \]
Монитор – это пара из mutex’а и набора условных переменных:

Взаимное исключение для защиты данных от одновременного изменения.
Условные переменные для ожидания.
Придумано Энтони Хоаром.
В java каждый объект имеет монитор с одной условной переменной:

synchronized == monitorenter + monitorexit.
wait, notify, notifyAll – для работы с условной переменной.
Что такое wait?

Может выходить из критической секции (монитора), чтобы другие потоки могли в нее попасть и поменять состояние объекта
Дожидается сигнала через условную переменную.
Снова входит в критическую секцию (в монитор), чтобы этот поток мог перепроверить состояние объекта и выполнить свою операцию если состояние подходящее.
Сигнал посылается через notify (сигнал одному ждущему потоку), notifyAll (сигнал всем ждущим потокам).
public class BlockingQueue<T> {
    private final T[] items;
    private final int n;
    private int head;
    private tail;

    public synchronized int size() {
        return (tail - head + n) % n;
    }

    // Если очередь пуста, возвращает null
    // полностью определен в любом состоянии
    public synchronized T poll0 {
        if (head == tail) return null;
        T result = items[head];
        items[head] = null;
        head = (head + 1) % n;
        return result;
    }

    // не определен для пустой очереди
    // Если очередь пуста -- ждет. Кидает exception == может блокироваться.
    // Цикл зачем? См. Object.wait: spurious wakeups are possible...
    public synchronized T poll throws Interruptedexception {
        while (head == tail) wait(); // критическая разница
        T result = items[head];
        items[head] = null;
        if ((tail + 1) % n == head) notifyAll(); // очередь была полна
        head = (head + 1) % n;
        return result;
    }

    // Сам метод не блокируется, но будит потоки, которые ждут
    // пока очередь станет не пуста
    // Нужно будить другие потоки, только если действительно
    // очередь становится не пуста.
    // Сигнал пойдет только после выхода из монитора (критической секции).
    public synchronized boolean offer(T item) {
        int next = (tail + 1) % n;
        if (next == head) return false;
        items[tail] = item;
        if (head == tail) notifyAll();
        tail = next;
    }

    // ждет пока очередь не полна и будет потоки, которые могут ждать пока
    // очередь станет не пуста
    public synchronized void put(T item) throws Interruptedexception {
        while (true) {
            int next = (tail + 1) % n;
            if (next == head) { wait(); continue; }
            items[tail] = item;
            if (head == tail) notifyAll();
            tail = next;
            return;
        }
    }

    // в методе take тоже нужно пытаться будить put, когда мы забрали последний
    // элемент
}
Рассмотрим еще раз разницу notify и notifyAll:

Нам нужно было использовать одну условную пееменную для двух условий: очередь не пуста и очередь не полна, поэтому пользуемся notifyAll.
Если бы для каждого условия использовалась бы отдельная переменная, notify было бы достаточно. Но у java есть только одна условная переменная на каждый монитор.
j.u.c.ReentrantLock спасает! Там есть методы всякие, которые предоставляет интерфейс Condition с методами await, signal, signalAll. Можно таким образом сделать эффективным take, в котом мы делаем все то же самое, что с интерфейсом wait/notify, но на локе и методами с похожими названиями. Но тут можно сделать два condition’а и делать на каждом signal, а не signalAll.

У каждого потока есть флаг interrupted.

Его ставит метод Thread.interrupt.
Его проверяют методы wait, await и так далее.
В случае обнаружения выставленного эти методы:
Прекращают ждать.
Сбрасывают флаг.
Кидают InterruptedException.
Что делать с ненужным InterruptedException? Если нужно реализовывать метод, который ждет, но не кидает InterruptedException, то interrupted флаг надо перевыставить. Тогда ожидание можно прерывать через Thread.interrupt.

Частая ошибка в ббилиотеках – забыли перевыставить interrupted флаг.

// возвращает null если прервали InterruptedException
public T takeOrNull() {
    try {
        return take();
    } catch (InterruptedException e) {
        // перевыставим флаг interrupted
        Thread.currentThread().interrupt();
        return null;
    }
}
Пишем поток, обрабатывающий очередь.

Заводим свой флаг, сигнализирующий что поток надо остановить. В отличии от флага interrupted, нет риска что какой-то сторонний метод его случайно сбросит.
для прерывания ожиданий нужен Thread.interrupt(). НИКОГДА не пользоваться Thread.stop().
Главный метод: метод run выполняется в отдельном потоке. Метод run выходит в случае прерывания.

SPSC очередь без блокировок и конвейер
Есть задачи и последовательные действия. $A₁…Aₙ$ (типа посчитать что-нибудь, преобразовать ответ, запаковать, записать в файл,..).

Пусть время выполнения действия $Aᵢ$ равно $tᵢ$. Тогда общее время на задачу равно $∑tᵢ$. Один поток в единицу времени выполняет $\frac{1}{∑tᵢ}$ задач.

Для увеличения пропускной способности сделаем конвейер на $n$ потоках.

Структура SPSC очереди.

Не блокирующийся offer: пишем без блокировок, поэтому важен порядок действий и точки линеаризации операций. CAS не нужен, только один producer меняет tail. Ожиданием займемся позже.

public boolean offer(T item) {
    // читаем один раз tail (только мы его меняем)
    int tail = this.tail;
    // здесь volatile чтение head (его меняет consumer)
    if (((tail+1) & mask) == head) return false; // полна
    items[tail] = item;
    // в самом конце передвинем tail
    this.tail = (tail + 1) & mask; // volatile write
    //        ^ это точка линеаризации операции offer
    return true;
}
LockSupport.park усыпляет текущий поток до тех пор:
Пока другой поток не вызовет unpark
Что-то еще…
LockSupport.unpark делает ???
Вот offer с unpark:

public boolean offer(T item) {
    int tail = this.tail;
    if (((tail+1) & mask) == head) return false; // полна
    items[tail] = item;
    this.tail = (tail + 1) & mask; // volatile write
    LockSupport.unpark(consumer); // разбудить ждущего потребителя
    return true;
}
public T take() throws InterruptedException {
    // это поможет при отладке
    assert Thread.currentThread() == consumer;
    // читаем один раз head
    int head = this.head; // volatile read
    while (true) {
        if (Thread.interrupted()) throw new InterruptedException();
        // здесь volatile чтение tail ( его меняет producer)
        if (head == tail) { LockSupport.park(); continue; }
        T result = items[head];
        items[head] = null;
        this.head = (head + 1) & mask;
        LockSupport.unpark(producer);
        return result;
    }
}
Блокирующийся take – разбор:

Нужен цикл ожидания (park может проснуться сам).
Нужно избежать ухода в бесконечный цикл.
Блокирующийся take – оптимальный unpark.

public T take() throws InterruptedException {
    // это поможет при отладке
    assert Thread.currentThread() == consumer;
    // читаем один раз head
    int head = this.head; // volatile read
    while (true) {
        if (Thread.interrupted()) throw new InterruptedException();
        // здесь volatile чтение tail ( его меняет producer)
        if (head == tail) { LockSupport.park(); continue; }
        T result = items[head];
        items[head] = null;
        this.head = (head + 1) & mask; // volatile write
        //        ^ это точка линеаризации операции take
        // если очередь была полна до операции (producer мог спать)
        if (((takl + 1) & mask) == head) LockSuppor.unpark(producer);
        return result;
    }
}
Все остальные операции аналогично.
Оптимизации SPSC очереди.
Блочная работа - можно доставать сразу несколько задач.
Обобщается на конвейер из n потоков.
$n$ потоков, работающие в конвейере, будут использовать общий циклический буфер.
Кладем задачу в буфер первым действием
Удалем задачу из буфера последним действием
У каждого потока есть свой index в буфере, а с $n = 2$ было tail == producer index, head == consumer index.
Каждый поток работает над задачами до index предыдущего потока в конвейере и следит, чтобы не упереться в следующий.
Практические наблюдения про конвейеры:

Конвейер (pipeline) имеет смысл, если отдельные действия по задаче примерно равны по продолжительности
Есть накладный расход на организацию. На быстрых действиях не выгодно.
Накладной расход на задачу можно уменьшить, обрабатывая элемениты пачками (batching).
Конвейер повышает пропускную способность (throughput) принося в жертву задержку (latency) – время обработки одной задачи от начала до конца.
